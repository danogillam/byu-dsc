{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Decision trees and Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male   22      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "2                             Heikkinen, Miss. Laina  female   26      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
       "4                           Allen, Mr. William Henry    male   35      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "datafile = '~/databases/titanic/train.csv'\n",
    "titanic = pd.read_csv(datafile)\n",
    "titanic[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "The goal of a decision tree is to create a model that predicts the value of a target variable based on several input variables. Each interior node corresponds to one of the input variables. Each leaf represents a value of the target variable given the values of the input variables represented by the path from the root to the leaf.\n",
    "\n",
    "![decision-tree example](https://upload.wikimedia.org/wikipedia/commons/f/f3/CART_tree_titanic_survivors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Decision trees\n",
    "* **classification tree** analysis is when the predicted outcome is the class to which the data belongs.\n",
    "* **regression tree** analysis is when the predicted outcome can be considered a real number (e.g. the price of a house, or a patient’s length of stay in a hospital)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cons of decision trees\n",
    "* low bias\n",
    "* high variance\n",
    "* prone to overfitting\n",
    "\n",
    "![biasvsvariance](http://www.mdpi.com/entropy/entropy-16-05242/article_deploy/html/images/entropy-16-05242f6-1024.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Random Forests?\n",
    "* Few tuning parameters\n",
    "* good performance\n",
    "* easy to use\n",
    "* don't need to standardize training data\n",
    "* automatically quantifies the importance of each feature for you.\n",
    "* an ensemble learning method\n",
    "    * taking multiple learning methods and aggregating their results\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests\n",
    "* a random forest is simply, a collection of decision trees.\n",
    "* Random Forests operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Random decision forests correct for decision trees' habit of overfitting to their training set.  \n",
    "* In particular, trees that are grown very deep tend to learn highly irregular patterns: they overfit their training sets, because they have low bias, but very high variance. Random forests are a way of averaging multiple deep decision trees, trained on different parts of the same training set, with the goal of reducing the variance.This comes at the expense of a small increase in the bias and some loss of interpretability, but generally greatly boosts the performance of the final model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bootstrap aggregating (Tree bagging)\n",
    "The training algorithm for random forests applies the general technique of **bootstrap aggregating**, or bagging, to tree learners.  \n",
    "\n",
    "This will reduce the variance without increasing bias!  \n",
    "This means that while the predictions of a single tree are highly sensitive to noise in its training set, the average of many trees is not, as long as the trees are not correlated. Simply training many trees on a single training set would give strongly correlated trees (or even the same tree many times, if the training algorithm is deterministic); bootstrap sampling is a way of de-correlating the trees by showing them different training sets.\n",
    "\n",
    "Given a training set $X = x_1, ..., x_n$ with responses $Y = y_1, ..., y_n$, bagging repeatedly (B times) selects a random sample with replacement of the training set and fits trees to these samples\n",
    "\n",
    "For $b = 1, ..., B$:\n",
    "1. Sample, with replacement, $n$ training examples from $X$, $Y$; call these $X_b, Y_b$.\n",
    "2. Train a decision or regression tree $f_b$ on $X_b, Y_b$.\n",
    "\n",
    "After training, predictions for unseen samples $x'$ can be made by averaging the predictions from all the individual regression trees on $x'$:\n",
    "\n",
    "$\\hat{f} = \\frac{1}{B} \\sum_{b=1}^B \\hat{f}_b (x')$\n",
    "\n",
    "or by taking the majority vote in the case of decision trees.  \n",
    ".  \n",
    ".  \n",
    "\n",
    "Given a new data point, we will run it through each decision tree in the forest and record how many trees vote for it to be a dead (blue) and how many vote for it to be alive (green). Whichever color gets the most votes, that’s the decision that the random forest makes. \n",
    "\n",
    "![combining trees](https://shapeofdata.files.wordpress.com/2013/07/randforest.png)\n",
    "\n",
    "The distributions defined by two decision trees are shown on the left and middle. The final distribution, shown on the right, comes from super-imposing the decision boundaries of the two individual trees. Each region in the resulting distribution is colored green if it is contained in green regions in both of the original two trees. It’s colored blue if it is contained in two blue regions, and grey if it is in one of each. These grey regions are ties.  \n",
    ".  \n",
    ".  \n",
    "\n",
    "##### Tuning parameters\n",
    "1. number of trees $B$\n",
    "    * more is better\n",
    "    * diminishing returns\n",
    "    * slower \n",
    "    * Typically, a few hundred to several thousand trees are used, depending on the size and nature of the training set. An optimal number of trees $B$ can be found using cross-validation, or by observing the 'out-of-bag error': the mean prediction error on each training sample $x_i$, using only the trees that did not have $x_i$ in their bootstrap sample. The training and test error tend to level off after some number of trees have been fit.\n",
    "    * too few trees, and not all samples will be accounted for\n",
    "2. number of features\n",
    "    * just like we randomly selected datapoints to creat our trees, we will also randomly select the features to make each tree.\n",
    "    * this decreases correlation between each tree. (same features $->$ same results) \n",
    "    * Typically, for a classification problem with p features, $\\sqrt{p}$ (rounded down) features are used in each split. For regression problems the inventors recommend p/3 (rounded down) with a minimum node size of 5 as the default.\n",
    "3. depth of trees\n",
    "    * if you go to deep, you risk overfitting the data\n",
    "    * it's hard to know ahead of time how deep the trees are and what limit to place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some Vocab\n",
    "* **class**: Each element of the domain of the classification. \n",
    "    * example: Survived, died\n",
    "* **feature**:  \n",
    "    * example: age, sibsp, sex\n",
    "* **node**: each node is labeled with a feature. The arcs coming from a node labeled with a feature are labeled with each of the possible values of the feature.\n",
    "* **Classification And Regression Tree (CART)** is a general name for decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using sklearn's Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get our data and format it a little bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def format_titanic_data(trainfile,testfile,predictors):\n",
    "    titanic = pd.read_csv(trainfile)\n",
    "    test = pd.read_csv(testfile)\n",
    "    '''convert data to usable values'''\n",
    "    for data in [titanic,test]:\n",
    "        #replace Sex with numbers\n",
    "        data.loc[data.Sex=='male','Sex']  = 0\n",
    "        data.loc[data.Sex=='female','Sex']= 1\n",
    "        #replace Embarked values with numbers\n",
    "        data.Embarked = data.Embarked.fillna('S')\n",
    "        data.loc[data.Embarked == 'S', 'Embarked']    =0\n",
    "        data.loc[data.Embarked == 'C', 'Embarked']    =1\n",
    "        data.loc[data.Embarked == 'Q', 'Embarked']    =2\n",
    "    \n",
    "    for field in predictors:\n",
    "        titanic[field] = titanic[field].fillna(titanic[field].median())\n",
    "        test[field] = test[field].fillna(titanic[field].median())\n",
    "    return titanic, test\n",
    "trainfile = '~/databases/titanic/train.csv'\n",
    "testfile = '~/databases/titanic/test.csv'\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "titanic,test = format_titanic_data(trainfile,testfile,predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### imputation\n",
    "* filling in missing values\n",
    "* median is usually used for decision trees\n",
    "* Column missing entirely?\n",
    "    * fill all the nans uniformly. (example is all zeros)\n",
    "    * because there is no variance in this column, it will never be chosen in the decision trees\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sklearn can do it just like pandas can! but only if data is all numbers\n",
    "def imputation_with_sklearn():\n",
    "    from sklearn.preprocessing import Imputer\n",
    "    imp = Imputer(strategy='median')\n",
    "    imp.fit(titanic)\n",
    "    imputed_train = imp.transform(titanic)\n",
    "    #remember, you need to use the median of the training data, not the test data\n",
    "    imputed_test= imp.transform(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#what if features are missing entirely?\n",
    "def missing_column_example():\n",
    "    mask = np.all(np.isnan(train),axis=0)\n",
    "    train[:,mask] = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement random forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.820426487093\n"
     ]
    }
   ],
   "source": [
    "#%%timeit\n",
    "alg = RandomForestClassifier(random_state=1, \n",
    "                             n_estimators=150,           #number of trees\n",
    "                             max_features='auto',        #number of features to consider at each split\n",
    "                             max_depth = None,           #depth of tree if known      \n",
    "                             min_samples_split=4,        #tree won't split unless at least this many samples in each branch\n",
    "                             min_samples_leaf=2,         #tree won't split unless at least this many samples in each leaf\n",
    "                             min_weight_fraction_leaf=0, #similar to min_samples_leaf except comparative\n",
    "                             max_leaf_nodes=None,        #contraining the depth by limiting the number of leaves\n",
    "                             n_jobs=4)                   #number of cores to use in calculation. default = 1, -1 means use all cores\n",
    "predictions = cross_validation.cross_val_predict(alg, \n",
    "                                                 titanic[predictors], \n",
    "                                                 titanic[\"Survived\"], \n",
    "                                                 cv=3)\n",
    "scores = cross_validation.cross_val_score(alg, \n",
    "                                          titanic[predictors], \n",
    "                                          titanic[\"Survived\"], \n",
    "                                          cv=3, \n",
    "                                          scoring ='accuracy' )\n",
    "print np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b9338cb10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lets play around with our number of trees\n",
    "trees = range(1,101,5)\n",
    "allscores = []\n",
    "for i in trees:\n",
    "    \n",
    "    alg = RandomForestClassifier(random_state=1, \n",
    "                                 n_estimators=i)\n",
    "    predictions = cross_validation.cross_val_predict(alg, \n",
    "                                                     titanic[predictors], \n",
    "                                                     titanic[\"Survived\"], \n",
    "                                                     cv=3)\n",
    "    scores = cross_validation.cross_val_score(alg, \n",
    "                                              titanic[predictors], \n",
    "                                              titanic[\"Survived\"], \n",
    "                                              cv=3, \n",
    "                                              scoring ='accuracy' )\n",
    "    allscores.append(np.mean(scores))\n",
    "plt.plot(trees,allscores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lets play around with our number of trees\n",
    "trees = range(1,301,25)\n",
    "allscores = []\n",
    "for i in trees:\n",
    "    \n",
    "    alg = RandomForestClassifier(random_state=1, \n",
    "                                 n_estimators=i)\n",
    "    predictions = cross_validation.cross_val_predict(alg, \n",
    "                                                     titanic[predictors], \n",
    "                                                     titanic[\"Survived\"], \n",
    "                                                     cv=3)\n",
    "    scores = cross_validation.cross_val_score(alg, \n",
    "                                              titanic[predictors], \n",
    "                                              titanic[\"Survived\"], \n",
    "                                              cv=3, \n",
    "                                              scoring ='accuracy' )\n",
    "    allscores.append(np.mean(scores))\n",
    "plt.plot(trees,allscores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 0 1 0 0 1 1 1 1 1 0 1 1 1 0 0 0 1 0 1 1 0\n",
      " 0 0 1 0 1 0 1 1 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 1 1 0 0 1 1 0 0 0\n",
      " 1 0 0 1 0 1 1 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0\n",
      " 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 1 1 0 0 1 0 1\n",
      " 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 1 0 1 0\n",
      " 1 1 1 0 0 1 0 0 0 1 0 0 1 0 0 1 1 1 1 1 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0\n",
      " 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 1 0 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 1 0 1 0 0 1 0\n",
      " 0 1 1 1 1 0 0 1 0 0 1]\n",
      "   PassengerId  Survived\n",
      "0          892         0\n",
      "1          893         0\n",
      "2          894         0\n",
      "3          895         1\n",
      "4          896         0\n",
      "5          897         0\n",
      "6          898         0\n",
      "7          899         0\n",
      "8          900         1\n",
      "9          901         0\n"
     ]
    }
   ],
   "source": [
    "alg.fit(titanic[predictors],\n",
    "        titanic[\"Survived\"])\n",
    "prediction = alg.predict(test[predictors])\n",
    "print prediction\n",
    "\n",
    "#save it \n",
    "submission = pd.DataFrame({ \"Survived\": prediction,\"PassengerId\":test.PassengerId})\n",
    "submission.to_csv('~/databases/titanic/submission_rf1',index=False)\n",
    "print submission[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature importances\n",
    "* basically, the closer to the root a feature is, the more important it is in predicting. sklearn has a built in method for finding the average importance of a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEACAYAAAC57G0KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZcBLUqMMeElqlAEvSY36/zwReS6MQr0/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1b91d94510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(np.arange(len(predictors)),alg.feature_importances_,tick_label=predictors)\n",
    "plt.xticks(np.arange(len(predictors))+.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sources\n",
    "https://shapeofdata.wordpress.com/2013/07/09/random-forests/\n",
    "https://en.wikipedia.org/wiki/Random_forest#Preliminaries:_decision_tree_learning  \n",
    "https://www.dataquest.io/mission/75/improving-your-submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
